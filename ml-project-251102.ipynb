{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a16fb66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1391923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default paths\n",
    "ROOT = Path(\"dataset\") # Root dataset directory\n",
    "\n",
    "PATH_NO_LABEL = ROOT / \"spotify_songs.csv\"\n",
    "PATH_INT_LABEL = ROOT / \"spotify_songs_with_genre_int.csv\"\n",
    "# PATH_ONE_HOT_LABEL = ROOT / \"filename.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfa1bc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "track_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "track_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "track_artist",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "track_popularity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "track_album_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "track_album_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "track_album_release_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "playlist_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "playlist_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "playlist_genre",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "playlist_subgenre",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "danceability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "energy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "key",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "loudness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mode",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "speechiness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "acousticness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "instrumentalness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "liveness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "valence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tempo",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "duration_ms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "genre_int",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "dfa113b8-c79d-4cc5-a0df-e84d01350504",
       "rows": [
        [
         "0",
         "6f807x0ima9a1j3VPbc7VN",
         "I Don't Care (with Justin Bieber) - Loud Luxury Remix",
         "Ed Sheeran",
         "66",
         "2oCs0DGTsRO98Gh5ZSl2Cx",
         "I Don't Care (with Justin Bieber) [Loud Luxury Remix]",
         "2019-06-14",
         "Pop Remix",
         "37i9dQZF1DXcZDD7cfEKhW",
         "pop",
         "dance pop",
         "0.748",
         "0.916",
         "6",
         "-2.634",
         "1",
         "0.0583",
         "0.102",
         "0.0",
         "0.0653",
         "0.518",
         "122.036",
         "194754",
         "0"
        ],
        [
         "1",
         "0r7CVbZTWZgbTCYdfa2P31",
         "Memories - Dillon Francis Remix",
         "Maroon 5",
         "67",
         "63rPSO264uRjW1X5E6cWv6",
         "Memories (Dillon Francis Remix)",
         "2019-12-13",
         "Pop Remix",
         "37i9dQZF1DXcZDD7cfEKhW",
         "pop",
         "dance pop",
         "0.726",
         "0.815",
         "11",
         "-4.969",
         "1",
         "0.0373",
         "0.0724",
         "0.00421",
         "0.357",
         "0.693",
         "99.972",
         "162600",
         "0"
        ],
        [
         "2",
         "1z1Hg7Vb0AhHDiEmnDE79l",
         "All the Time - Don Diablo Remix",
         "Zara Larsson",
         "70",
         "1HoSmj2eLcsrR0vE9gThr4",
         "All the Time (Don Diablo Remix)",
         "2019-07-05",
         "Pop Remix",
         "37i9dQZF1DXcZDD7cfEKhW",
         "pop",
         "dance pop",
         "0.675",
         "0.931",
         "1",
         "-3.432",
         "0",
         "0.0742",
         "0.0794",
         "2.33e-05",
         "0.11",
         "0.613",
         "124.008",
         "176616",
         "0"
        ],
        [
         "3",
         "75FpbthrwQmzHlBJLuGdC7",
         "Call You Mine - Keanu Silva Remix",
         "The Chainsmokers",
         "60",
         "1nqYsOef1yKKuGOVchbsk6",
         "Call You Mine - The Remixes",
         "2019-07-19",
         "Pop Remix",
         "37i9dQZF1DXcZDD7cfEKhW",
         "pop",
         "dance pop",
         "0.718",
         "0.93",
         "7",
         "-3.778",
         "1",
         "0.102",
         "0.0287",
         "9.43e-06",
         "0.204",
         "0.277",
         "121.956",
         "169093",
         "0"
        ],
        [
         "4",
         "1e8PAfcKUYoKkxPhrHqw4x",
         "Someone You Loved - Future Humans Remix",
         "Lewis Capaldi",
         "69",
         "7m7vv9wlQ4i0LFuJiE2zsQ",
         "Someone You Loved (Future Humans Remix)",
         "2019-03-05",
         "Pop Remix",
         "37i9dQZF1DXcZDD7cfEKhW",
         "pop",
         "dance pop",
         "0.65",
         "0.833",
         "1",
         "-4.672",
         "1",
         "0.0359",
         "0.0803",
         "0.0",
         "0.0833",
         "0.725",
         "123.976",
         "189052",
         "0"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>track_album_id</th>\n",
       "      <th>track_album_name</th>\n",
       "      <th>track_album_release_date</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_genre</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>genre_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6f807x0ima9a1j3VPbc7VN</td>\n",
       "      <td>I Don't Care (with Justin Bieber) - Loud Luxur...</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>66</td>\n",
       "      <td>2oCs0DGTsRO98Gh5ZSl2Cx</td>\n",
       "      <td>I Don't Care (with Justin Bieber) [Loud Luxury...</td>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.518</td>\n",
       "      <td>122.036</td>\n",
       "      <td>194754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0r7CVbZTWZgbTCYdfa2P31</td>\n",
       "      <td>Memories - Dillon Francis Remix</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>67</td>\n",
       "      <td>63rPSO264uRjW1X5E6cWv6</td>\n",
       "      <td>Memories (Dillon Francis Remix)</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.693</td>\n",
       "      <td>99.972</td>\n",
       "      <td>162600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1z1Hg7Vb0AhHDiEmnDE79l</td>\n",
       "      <td>All the Time - Don Diablo Remix</td>\n",
       "      <td>Zara Larsson</td>\n",
       "      <td>70</td>\n",
       "      <td>1HoSmj2eLcsrR0vE9gThr4</td>\n",
       "      <td>All the Time (Don Diablo Remix)</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.613</td>\n",
       "      <td>124.008</td>\n",
       "      <td>176616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75FpbthrwQmzHlBJLuGdC7</td>\n",
       "      <td>Call You Mine - Keanu Silva Remix</td>\n",
       "      <td>The Chainsmokers</td>\n",
       "      <td>60</td>\n",
       "      <td>1nqYsOef1yKKuGOVchbsk6</td>\n",
       "      <td>Call You Mine - The Remixes</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.778</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.277</td>\n",
       "      <td>121.956</td>\n",
       "      <td>169093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1e8PAfcKUYoKkxPhrHqw4x</td>\n",
       "      <td>Someone You Loved - Future Humans Remix</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>69</td>\n",
       "      <td>7m7vv9wlQ4i0LFuJiE2zsQ</td>\n",
       "      <td>Someone You Loved (Future Humans Remix)</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.725</td>\n",
       "      <td>123.976</td>\n",
       "      <td>189052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                                         track_name  \\\n",
       "0  6f807x0ima9a1j3VPbc7VN  I Don't Care (with Justin Bieber) - Loud Luxur...   \n",
       "1  0r7CVbZTWZgbTCYdfa2P31                    Memories - Dillon Francis Remix   \n",
       "2  1z1Hg7Vb0AhHDiEmnDE79l                    All the Time - Don Diablo Remix   \n",
       "3  75FpbthrwQmzHlBJLuGdC7                  Call You Mine - Keanu Silva Remix   \n",
       "4  1e8PAfcKUYoKkxPhrHqw4x            Someone You Loved - Future Humans Remix   \n",
       "\n",
       "       track_artist  track_popularity          track_album_id  \\\n",
       "0        Ed Sheeran                66  2oCs0DGTsRO98Gh5ZSl2Cx   \n",
       "1          Maroon 5                67  63rPSO264uRjW1X5E6cWv6   \n",
       "2      Zara Larsson                70  1HoSmj2eLcsrR0vE9gThr4   \n",
       "3  The Chainsmokers                60  1nqYsOef1yKKuGOVchbsk6   \n",
       "4     Lewis Capaldi                69  7m7vv9wlQ4i0LFuJiE2zsQ   \n",
       "\n",
       "                                    track_album_name track_album_release_date  \\\n",
       "0  I Don't Care (with Justin Bieber) [Loud Luxury...               2019-06-14   \n",
       "1                    Memories (Dillon Francis Remix)               2019-12-13   \n",
       "2                    All the Time (Don Diablo Remix)               2019-07-05   \n",
       "3                        Call You Mine - The Remixes               2019-07-19   \n",
       "4            Someone You Loved (Future Humans Remix)               2019-03-05   \n",
       "\n",
       "  playlist_name             playlist_id playlist_genre  ... loudness  mode  \\\n",
       "0     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   -2.634     1   \n",
       "1     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   -4.969     1   \n",
       "2     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   -3.432     0   \n",
       "3     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   -3.778     1   \n",
       "4     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   -4.672     1   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       0.0583        0.1020          0.000000    0.0653    0.518  122.036   \n",
       "1       0.0373        0.0724          0.004210    0.3570    0.693   99.972   \n",
       "2       0.0742        0.0794          0.000023    0.1100    0.613  124.008   \n",
       "3       0.1020        0.0287          0.000009    0.2040    0.277  121.956   \n",
       "4       0.0359        0.0803          0.000000    0.0833    0.725  123.976   \n",
       "\n",
       "   duration_ms  genre_int  \n",
       "0       194754          0  \n",
       "1       162600          0  \n",
       "2       176616          0  \n",
       "3       169093          0  \n",
       "4       189052          0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_label_df = pd.read_csv(PATH_INT_LABEL)\n",
    "int_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a1a5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import numpy as np\n",
    "\n",
    "# # feature_col 변수가 아직 정의되지 않았을 때도 안전하게 동작하도록 컬럼 리스트를 직접 사용\n",
    "# features = [\"track_popularity\", \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_ms\"]\n",
    "\n",
    "# # 1) 라벨 진단 및 0-based 재매핑 (CrossEntropy는 0-based 정수 라벨 필요)\n",
    "# print('genre_int dtype, min, max:', int_label_df['genre_int'].dtype, int_label_df['genre_int'].min(), int_label_df['genre_int'].max())\n",
    "# print('Label distribution:\\n', int_label_df['genre_int'].value_counts())\n",
    "# if int_label_df['genre_int'].min() != 0 or int_label_df['genre_int'].nunique() != (int_label_df['genre_int'].max() + 1):\n",
    "#     int_label_df['genre_int'], uniques = pd.factorize(int_label_df['genre_int'])\n",
    "#     print('Remapped labels to 0..C-1. #original labels:', len(uniques))\n",
    "\n",
    "# # 2) Feature 스케일링: duration_ms 같은 큰 값 때문에 초기 logits/손실이 매우 큼\n",
    "# scaler = StandardScaler()\n",
    "# int_label_df[features] = scaler.fit_transform(int_label_df[features])\n",
    "# print('Feature means (post-scale):', np.round(int_label_df[features].mean().values,3))\n",
    "# print('Feature stds  (post-scale):', np.round(int_label_df[features].std().values,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b11add09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre_int dtype, min, max: int64 0 5\n",
      "Label distribution:\n",
      " genre_int\n",
      "5    6043\n",
      "1    5746\n",
      "0    5507\n",
      "3    5431\n",
      "4    5155\n",
      "2    4951\n",
      "Name: count, dtype: int64\n",
      "Feature means (post-scale): [-0.  0.  0. -0.  0. -0. -0. -0.  0. -0.  0.  0. -0.]\n",
      "Feature stds  (post-scale): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "features = [\"track_popularity\",\"danceability\",\"energy\",\"key\",\"loudness\",\"mode\",\n",
    "            \"speechiness\",\"acousticness\",\"instrumentalness\",\"liveness\",\"valence\",\n",
    "            \"tempo\",\"duration_ms\"]\n",
    "\n",
    "# --- (A) log1p 적용: 비음수 & 고왜도 컬럼 ---\n",
    "log_cols = [\"duration_ms\", \"instrumentalness\", \"liveness\", \"speechiness\", \"acousticness\"]\n",
    "for c in log_cols:\n",
    "    # 결측/음수 방어 (이 컬럼들은 보통 0~1 or 양수지만 안전망)\n",
    "    x = int_label_df[c].to_numpy()\n",
    "    x = np.where(x < 0, 0.0, x)       # 음수면 0으로 클립\n",
    "    int_label_df[c] = np.log1p(x)     # log(1+x)\n",
    "\n",
    "# (참고) loudness는 dB(음수 포함) → log 변환 하지 말고 그냥 스케일만\n",
    "# key(0~11), mode(0/1)는 범주/이진 → 그대로 두거나 필요시 원-핫 (지금은 그대로)\n",
    "\n",
    "# --- (B) 라벨 0-based 보장 ---\n",
    "print('genre_int dtype, min, max:', int_label_df['genre_int'].dtype, int_label_df['genre_int'].min(), int_label_df['genre_int'].max())\n",
    "print('Label distribution:\\n', int_label_df['genre_int'].value_counts())\n",
    "if int_label_df['genre_int'].min() != 0 or int_label_df['genre_int'].nunique() != int_label_df['genre_int'].max()+1:\n",
    "    int_label_df['genre_int'], uniques = pd.factorize(int_label_df['genre_int'])\n",
    "    print('Remapped labels to 0..C-1. #original labels:', len(uniques))\n",
    "\n",
    "# --- (C) 스케일링 ---\n",
    "scaler = StandardScaler()\n",
    "int_label_df[features] = scaler.fit_transform(int_label_df[features])\n",
    "print('Feature means (post-scale):', np.round(int_label_df[features].mean().values, 3))\n",
    "print('Feature stds  (post-scale):',  np.round(int_label_df[features].std().values, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea02bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = [\"track_popularity\", \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_ms\"]\n",
    "label_col = [\"genre_int\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fc79447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate(model, dataloader, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Evaluate a classification model on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The classification model to evaluate.\n",
    "        dataloader (DataLoader): DataLoader providing batches of {\"X\": features, \"y\": labels}.\n",
    "        device (str, optional): Device to run evaluation on (\"cpu\" or \"cuda\"). Default is \"cpu\".\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - \"accuracy\": Overall accuracy of predictions.\n",
    "            - \"f1_macro\": Macro-averaged F1 score across all classes.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X = batch[\"X\"].to(device)\n",
    "            y = batch[\"y\"].to(device)\n",
    "            logits = model(X)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(y.cpu().tolist())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1_macro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f186a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MLP based Classifier ===\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=128, num_classes=6):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, hidden)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden)\n",
    "        self.fc2 = nn.Linear(hidden, num_classes)\n",
    "        # 가중치 초기화로 초기 출력 폭을 줄임\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5fd14e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols=feature_col, label_col=label_col):\n",
    "        self.X = torch.tensor(df[feature_cols].to_numpy(dtype=\"float32\"))\n",
    "        # label_col은 리스트이므로 2D가 될 수 있음 -> 1D로 변환\n",
    "        self.y = torch.tensor(df[label_col].to_numpy().ravel(), dtype=torch.long)\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        return {\"X\": self.X[idx], \"y\": self.y[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed64af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Prepare test dataset and data loader ===\n",
    "dataset = ProductDataset(\n",
    "    df=int_label_df,\n",
    "    feature_cols=feature_col,\n",
    "    label_col=label_col,\n",
    ")\n",
    "\n",
    "# === Split training dataset into train/validation sets (50:25:25) ===\n",
    "val_ratio, test_ratio = 0.25, 0.25\n",
    "val_size  = int(len(dataset) * val_ratio)\n",
    "test_size  = int(len(dataset) * test_ratio)\n",
    "train_size = len(dataset) - val_size - test_size\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "train_split, val_split, test_split = random_split(dataset, [train_size, val_size, test_size], generator=g)\n",
    "\n",
    "# === Create DataLoaders for training and validation ===\n",
    "train_loader = DataLoader(train_split, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_loader   = DataLoader(val_split,   batch_size=64, shuffle=False, drop_last=True)\n",
    "test_loader  = DataLoader(test_split, batch_size=64, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc766bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Initialize model and optimizer ===\n",
    "in_dim = next(iter(train_loader))[\"X\"].shape[1]  # 13\n",
    "num_classes = int(int_label_df['genre_int'].nunique())  # 정확한 라벨 개수\n",
    "model = Classifier(in_dim=in_dim, hidden=256, num_classes=num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c8ac8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_result(metrics: dict, stage=\"val\", is_improved=False):\n",
    "    \"\"\"\n",
    "    Print evaluation results (accuracy, F1-macro).\n",
    "    \n",
    "    Args:\n",
    "        metrics: dict with keys 'accuracy' and 'f1_macro'\n",
    "        stage: string label (e.g., \"val\", \"test\")\n",
    "        is_improved: mark with '*' if results improved\n",
    "    \"\"\"\n",
    "    star = \" *\" if is_improved else \"\"\n",
    "    print(f\"[{stage.upper():4}] Acc: {metrics['accuracy']:.4f} | \"\n",
    "          f\"F1-macro: {metrics['f1_macro']:.4f}{star}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b39970be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = next(iter(train_loader))\n",
    "# print(\"X:\", b[\"X\"].shape, b[\"X\"].mean().item(), b[\"X\"].std().item())\n",
    "# print(\"y range:\", int(torch.min(b[\"y\"])), int(torch.max(b[\"y\"])))\n",
    "\n",
    "# c = next(iter(val_loader))\n",
    "# print(\"X:\", c[\"X\"].shape, c[\"X\"].mean().item(), c[\"X\"].std().item())\n",
    "# print(\"y range:\", int(torch.min(c[\"y\"])), int(torch.max(c[\"y\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35016988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 513/513 [00:02<00:00, 191.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 1.5095\n",
      "[TEST] Acc: 0.5033 | F1-macro: 0.4906\n",
      "[VALIDATION] Acc: 0.5004 | F1-macro: 0.4875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 513/513 [00:02<00:00, 189.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 1.4209\n",
      "[TEST] Acc: 0.5127 | F1-macro: 0.5006\n",
      "[VALIDATION] Acc: 0.5024 | F1-macro: 0.4897\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 513/513 [00:02<00:00, 246.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 1.3858\n",
      "[TEST] Acc: 0.5142 | F1-macro: 0.5022\n",
      "[VALIDATION] Acc: 0.5106 | F1-macro: 0.4990\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 513/513 [00:02<00:00, 191.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 1.3731\n",
      "[TEST] Acc: 0.5170 | F1-macro: 0.5071\n",
      "[VALIDATION] Acc: 0.5166 | F1-macro: 0.5059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 513/513 [00:01<00:00, 272.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 1.3610\n",
      "[TEST] Acc: 0.5089 | F1-macro: 0.5060\n",
      "[VALIDATION] Acc: 0.5127 | F1-macro: 0.5090\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 513/513 [00:01<00:00, 269.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 1.3559\n",
      "[TEST] Acc: 0.5194 | F1-macro: 0.5120\n",
      "[VALIDATION] Acc: 0.5186 | F1-macro: 0.5095\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 513/513 [00:02<00:00, 248.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 1.3536\n",
      "[TEST] Acc: 0.5199 | F1-macro: 0.5122\n",
      "[VALIDATION] Acc: 0.5215 | F1-macro: 0.5130\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 513/513 [00:01<00:00, 270.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 1.3502\n",
      "[TEST] Acc: 0.5225 | F1-macro: 0.5115\n",
      "[VALIDATION] Acc: 0.5192 | F1-macro: 0.5090\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 513/513 [00:02<00:00, 218.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 1.3418\n",
      "[TEST] Acc: 0.5253 | F1-macro: 0.5160\n",
      "[VALIDATION] Acc: 0.5244 | F1-macro: 0.5148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 513/513 [00:01<00:00, 260.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 1.3457\n",
      "[TEST] Acc: 0.5209 | F1-macro: 0.5155\n",
      "[VALIDATION] Acc: 0.5192 | F1-macro: 0.5126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 513/513 [00:02<00:00, 220.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 1.3404\n",
      "[TEST] Acc: 0.5227 | F1-macro: 0.5112\n",
      "[VALIDATION] Acc: 0.5190 | F1-macro: 0.5071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 513/513 [00:02<00:00, 196.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 1.3423\n",
      "[TEST] Acc: 0.5281 | F1-macro: 0.5166\n",
      "[VALIDATION] Acc: 0.5308 | F1-macro: 0.5187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 513/513 [00:02<00:00, 203.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 1.3340\n",
      "[TEST] Acc: 0.5289 | F1-macro: 0.5178\n",
      "[VALIDATION] Acc: 0.5281 | F1-macro: 0.5160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 513/513 [00:01<00:00, 265.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 1.3350\n",
      "[TEST] Acc: 0.5284 | F1-macro: 0.5155\n",
      "[VALIDATION] Acc: 0.5292 | F1-macro: 0.5159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 513/513 [00:02<00:00, 198.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 1.3299\n",
      "[TEST] Acc: 0.5281 | F1-macro: 0.5172\n",
      "[VALIDATION] Acc: 0.5275 | F1-macro: 0.5160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 513/513 [00:02<00:00, 253.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 1.3305\n",
      "[TEST] Acc: 0.5245 | F1-macro: 0.5186\n",
      "[VALIDATION] Acc: 0.5282 | F1-macro: 0.5208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 513/513 [00:02<00:00, 249.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 1.3290\n",
      "[TEST] Acc: 0.5250 | F1-macro: 0.5113\n",
      "[VALIDATION] Acc: 0.5254 | F1-macro: 0.5107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 513/513 [00:02<00:00, 213.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 1.3304\n",
      "[TEST] Acc: 0.5330 | F1-macro: 0.5251\n",
      "[VALIDATION] Acc: 0.5342 | F1-macro: 0.5266\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 513/513 [00:02<00:00, 191.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 1.3272\n",
      "[TEST] Acc: 0.5253 | F1-macro: 0.5195\n",
      "[VALIDATION] Acc: 0.5294 | F1-macro: 0.5237\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 513/513 [00:01<00:00, 276.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train Loss: 1.3249\n",
      "[TEST] Acc: 0.5264 | F1-macro: 0.5204\n",
      "[VALIDATION] Acc: 0.5286 | F1-macro: 0.5217\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 513/513 [00:02<00:00, 193.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Train Loss: 1.3247\n",
      "[TEST] Acc: 0.5287 | F1-macro: 0.5206\n",
      "[VALIDATION] Acc: 0.5294 | F1-macro: 0.5201\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 513/513 [00:02<00:00, 214.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Train Loss: 1.3260\n",
      "[TEST] Acc: 0.5312 | F1-macro: 0.5217\n",
      "[VALIDATION] Acc: 0.5323 | F1-macro: 0.5220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 513/513 [00:02<00:00, 193.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Train Loss: 1.3209\n",
      "[TEST] Acc: 0.5244 | F1-macro: 0.5065\n",
      "[VALIDATION] Acc: 0.5326 | F1-macro: 0.5138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 513/513 [00:02<00:00, 222.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Train Loss: 1.3196\n",
      "[TEST] Acc: 0.5277 | F1-macro: 0.5157\n",
      "[VALIDATION] Acc: 0.5292 | F1-macro: 0.5158\n",
      "\n",
      "No imporvement for 6 Epochs\n"
     ]
    }
   ],
   "source": [
    "# === Training loop with validation, test evaluation, and early stopping ===\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "best_score = 0\n",
    "wait_time = 6\n",
    "cnt = 0\n",
    "best_model_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "train_losses, val_acc_list, test_acc_list = [], [], []\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # --- Training phase ---\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        X, y = batch[\"X\"].to(device), batch[\"y\"].to(device)\n",
    "        # if y.dim() == 2 and y.size(1) == 1:\n",
    "        #     y = y.squeeze(1)          # (B,1) → (B,)\n",
    "        logits = model(X)\n",
    "        loss = F.cross_entropy(logits, y, label_smoothing=0.05)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / max(1, len(train_loader))\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f\"[Epoch {epoch}] Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    test_result = evaluate(model, test_loader, device=device)\n",
    "    test_acc = float(test_result.get(\"accuracy\", 0.0))\n",
    "    test_acc_list.append(test_acc)\n",
    "    print_eval_result(test_result, stage=\"test\")\n",
    "    \n",
    "    val_result = evaluate(model, val_loader, device=device)\n",
    "    val_acc = float(val_result.get(\"accuracy\", 0.0))\n",
    "    val_acc_list.append(val_acc)\n",
    "    print_eval_result(val_result, stage=\"validation\")\n",
    "    print()\n",
    "\n",
    "    if val_acc > best_score:\n",
    "        best_score = val_acc\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        cnt = 0\n",
    "    else:\n",
    "        cnt += 1\n",
    "        if cnt >= wait_time:\n",
    "            print(f\"No imporvement for {cnt} Epochs\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "184d64bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINAL_TEST] Acc: 0.5330 | F1-macro: 0.5251\n"
     ]
    }
   ],
   "source": [
    "# === Load the best model and evaluate on the test set ===\n",
    "model.load_state_dict(best_model_state) \n",
    "\n",
    "final_test_result = evaluate(model, test_loader, device=device)\n",
    "print_eval_result(final_test_result, stage=\"final_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caa81fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스포티파이 api 이용해서 뭔가 해보려고 했으나 policy update로 인해 무산\n",
    "\n",
    "# import pprint\n",
    "# from spotifyyy import *\n",
    "\n",
    "# genre_dict = {0: 'pop', 1: 'rap', 2: 'rock', 3: 'r&b', 4: 'latin', 5: 'edm'}\n",
    "# query = input()\n",
    "\n",
    "# respond = get_track_by_search(query)\n",
    "# pprint.pprint(respond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9d93df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song: Poetic Justice | artist: Kendrick Lamar\n",
      "answer: rap | pred: rap | conf: 1.0000\n",
      "top-k: [('rap', 1.0), ('r&b', 6.376916217298856e-10), ('edm', 3.5217558686579975e-17)]\n"
     ]
    }
   ],
   "source": [
    "# 그래서 걍 랜덤으로 한 행 뽑아서 테스트 해봄\n",
    "\n",
    "genre_dict = {0: 'pop', 1: 'rap', 2: 'rock', 3: 'r&b', 4: 'latin', 5: 'edm'}\n",
    "row = int_label_df.sample(n=1, random_state=1).iloc[0]\n",
    "\n",
    "song_name   = row[\"track_name\"]\n",
    "artist_name = row[\"track_artist\"]\n",
    "answer      = row.get(\"playlist_genre\", None)\n",
    "\n",
    "# === 스케일러에 feature 이름을 유지해 전달 ===\n",
    "x_df = pd.DataFrame([row[features]], columns=features)\n",
    "x_np = scaler.transform(x_df)[0]\n",
    "\n",
    "# === 모델 추론 ===\n",
    "model.eval(); model.to(device)\n",
    "x = torch.tensor(x_np, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(x)\n",
    "    probs  = F.softmax(logits, dim=1)[0]\n",
    "    pred_id = int(torch.argmax(probs).item())\n",
    "    pred_conf = float(probs[pred_id].item())\n",
    "\n",
    "pred_genre = genre_dict[pred_id]\n",
    "\n",
    "print(f\"song: {song_name} | artist: {artist_name}\")\n",
    "if answer is not None:\n",
    "    print(f\"answer: {answer} | pred: {pred_genre} | conf: {pred_conf:.4f}\")\n",
    "else:\n",
    "    print(f\"pred: {pred_genre} | conf: {pred_conf:.4f}\")\n",
    "\n",
    "# 확률 Top-k 장르들 보기\n",
    "k = 3\n",
    "top_p, top_i = torch.topk(probs, k)\n",
    "print(\"top-k:\", [(genre_dict[int(i)], float(p)) for p, i in zip(top_p, top_i)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
